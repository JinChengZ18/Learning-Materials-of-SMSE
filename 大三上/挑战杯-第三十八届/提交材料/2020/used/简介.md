氢脆问题自 20 世纪 40 年代被发现以来，一直是严重威胁金属材料使用安全的一个重大问题。就氢脆问题而言，高强度金属材料往往对其敏感程度更高，因而限制了其在一般环境条件下的使用；近年来随着氢能源的兴起，如何制造一种能在高强氢分压下保持结构强度的材料，也成为一种紧迫的需求。

针对氢脆问题人们提出了多种机制，包括氢致位错发射理论、氢致局部塑形变形理论、氢致微裂缝聚合理论、氢压理论、弱键理论、氢降低表面能理论、氢致相变理论等其他理论。但是这些描述氢脆的理论都有其适用范围和对象，缺乏一种统一的描述。而从本质上来讲，氢脆现象是由于氢与金属产生交互作用而引起的。所以基于第一性原理的数值模拟的计算方法对于研究氢与金属基体交互作用的微观机理而言是一种有效可行的手段。

 

就本课题的定位而言，则主要是通过研究对材料本身性质不同而导致的对于氢脆响应的不同，注重研究结构与性质的关系。研究的主要方法是利用开源LAMMPS分子动力学软件结合 Python 二次开发实现对材料氢脆现象与材料中氢的扩散和偏聚过程的模拟，并采用机器学习算法对结果进行模型拟合，找出一定规律。



传统开发新材料的过程，都采用的试错法，实验步骤繁琐，研发周期长，浪费资源。随着计算机的发展，许多诸如第一性原理计算、相场模拟、有限元分析等手段随之出现，用以进行材料的结构以及性能方面的计算，但是往往计算量大，费用大。而超算技术介入材料科学带来的巨大信息使得结合材料数据库、数值模拟数据和机器学习方法驱动材料发现和材料设计并预测材料性能成为可能。

 

为了解决传统方法周期长、成本高问题，可以将所有的实验数据，计算模拟数据，整合起来形成具有一定规模的数据库；在数据库中，根据材料的某些属性可以建立机器学习模型，便可快速对材料的性能进行预测，甚至是设计新材料，解决相关问题。





One of the fundamental challenges in materials science is the establishment of high value correlations between the process parameters of a given material and its associated performance characteristics, while accounting for the hierarchical nature of the material's internal structure [1]. Such correlations form the foundations of the field of materials science and engineering, and are generally referred as PSP (process-structure-property) linkages. These linkages are central to all efforts aimed at the development and deployment of new or improved materials for advanced technologies. 

材料科学的基本挑战之一是在给定材料的工艺参数与其相关性能特征之间建立高值相关性，同时考虑材料内部结构的层次性[1]。这种相互关系构成了材料科学和工程领域的基础，通常被称为PSP（工艺-结构-性质）联系。这些联系对于所有旨在开发和部署新的或改进的先进技术材料的努力至关重要。 

The main hurdle in the establishment of the PSP linkages comes from the fact that the material internal structure spans multiple hierarchical length/structure scales. Furthermore, the rich complexity of features exhibited by different materials at different length/structure scales has greatly impeded the efforts aimed at developing a universally applicable framework. Furthermore, in spite of the tremendous advances made in the experimental characterization of the material internal structure [8,9], currently available techniques are not yet capable of producing sufficiently large ensembles of experimentally measured datasets that can be mined for PSP linkages. For this and many other reasons, multiscale models [10,12] offer the most practical path forward for establishing and demonstrating the critical methodologies needed for extracting and validating high value PSP linkages spanning the multiple length/structure scales involved, i.e., the atomic scale to the continuum.

建立PSP连接的主要障碍来自于材料内部结构跨越多个层次长度/结构尺度的事实。此外，不同材料在不同长度/结构尺度上所表现出的丰富的复杂性极大地阻碍了旨在开发一个普遍适用的框架的努力。此外，目前还无法对大量的内部结构进行实验测量，但仍无法获得大量的内部结构数据。基于这一点和许多其他原因，多尺度模型[10,12]为建立和证明提取和验证跨越多个长度/结构尺度的高值PSP连接（即原子尺度到连续体）所需的关键方法提供了最实际的途径。

Emerging toolsets of data science and informatics offer tremendous potential for mining the high value PSP linkages from aggregated and curated materials datasets [13e16]. A large fraction of such effort in current literature has only considered relatively simple definitions of the material that included mainly the overall chemical composition of the material. In recent work [17-20], our research group has championed a new materials data science framework that explicitly accounts for the complex hierarchical material structure. Called Materials Knowledge Systems (MKS) [21-24], this new framework employs spatial correlations to quantify the material structure (at each structure/length scale of interest) and **principal component analyses (PCA) to obtain the salient low-dimensional measures needed to represent the complex material structure in the PSP linkages of interest**. This new framework has been successfully demonstrated with several case studies dealing with the mesoscale structure of the material [25-30]. Only recently, the application of this framework is being extended to the atomic structure of materials [17,31].

新兴的数据科学和信息学工具集为从聚合和管理的材料数据集中挖掘高价值的PSP链接提供了巨大的潜力[13-16]。在目前的文献中，这种努力的很大一部分只考虑了相对简单的材料定义，主要包括材料的整体化学成分。在最近的工作[17-20]中，我们的研究小组倡导了一种新的材料数据科学框架，明确说明了复杂的分层材料结构。在这种新的材料结构中，用主成分分析法（MKS）[21-24]来量化所需的材料结构的空间关联性。这一新的框架已经成功地通过几个关于材料中尺度结构的案例研究加以证明[25-30]。直到最近，这个框架的应用才扩展到材料的原子结构[17,31]。 

There is tremendous value in casting the rich, physics-driven, results of the molecular mechanics (MM) or molecular dynamics (MD) simulations as PSP linkages. However, it is not immediately obvious what variables should be selected to describe the process parameters in such linkages. We argue that the process variables selected should describe the conditions imposed to control or modify the material structure. These might include the thermodynamic ensemble, force fields, and applied loads. At the atomic scale, these can also be captured effectively by the configurational constraints imposed on the material structure. More specifically, the macro degrees of freedom imposed as input in the GB simulations would constitute the process variables. The “structure” would correspond to the elements, configuration and bonding structure of the atoms in a given composition. For atomistic simulations, a commonly employed metric for quantifying structure is the pair correlation function (PCF). The application of MKS framework relies on discretized representation of the material structure, both for quantification of the statistics (i.e., spatial correlations) as well as obtaining low dimensional representations (i.e., PCA). In prior work using microscopy images (e.g., optical, SEM) [32], discrete representations were obtained easily because the image itself is often stored as pixelated values. For point-cloud data such as the results of MD simulations studied here, we need to pay careful attention to how this is accomplished. If the PCFs are computed using the atomic positions directly, they would exhibit very sharp peaks (since the PCF is essentially a weighted sum of Dirac-delta functions located at the specific distances realized in the given atomic structure). This poses two main challenges: (i) The discrete representations of the PCF become very sensitive to the binning, especially as the bin size decreases (in efforts to capture the PCF accurately in their discretized representations). (ii) The discretized representation of the PCF would exhibit a large number of zero values for many of the bins (because of the Dirac-delta nature of the PCFs). Furthermore, if the PCF value for a bin is zero for all the atomic structures studied (this is very likely to happen with any point-cloud datasets), then the PCA can be hindered by rank deficiency because there is simply no information on that specific bin to compute the corresponding component in all of the orthonormal eigenvectors comprising the PCA basis. Therefore, it is clear that some form of smoothing is essential for the application of the MKS framework on the point-cloud atomic structure datasets. In the present work, this was accomplished using Epanechnikov kernels, which effectively amounts to placing a sphere around each atomic position and then discretizing the volumetric space to obtain discretized, but robust, representations of the PCF useful to establishing the desired PSP linkages. 

将分子力学（MM）或分子动力学（MD）模拟出丰富的、物理驱动的结果转化成 PSP 关系具有巨大的价值。然而，目前还不清楚应该选择什么变量来描述这种联系中的工艺参数。我们认为，选择的工艺变量应描述控制或修改材料结构的条件。这些可能包括热力学系综、力场和外加载荷。在原子尺度上，这些也可以通过施加在材料结构上的构型约束有效地捕捉到。更具体地说，作为GB模拟输入的宏观自由度将构成过程变量。“结构”对应于给定成分中原子的元素、构型和键合结构。**对于原子模拟，量化结构的一个常用量度是对相关函数（PCF）**。MKS框架的应用依赖于材料结构的离散化表示，既可以量化统计（即空间相关性），也可以获得低维表示（即PCA）。在先前使用显微镜图像（例如光学、SEM）[32]的工作中，由于图像本身通常存储为像素值，因此很容易获得离散表示。对于点云数据，例如这里研究的MD模拟结果，我们需要仔细关注这是如何实现的。**如果直接使用原子位置来计算PCF，它们会出现非常尖锐的峰值（因为PCF本质上是在给定原子结构中实现的特定距离处的狄拉克δ函数的加权和）。这就带来了两个主要的挑战**：（i）PCF的离散表示对binning变得非常敏感，特别是当bin大小减小时（努力在离散表示中准确地捕捉PCF）。（ii）PCF的离散化表示将显示许多箱的大量零值（因为PCF的狄拉克函数性质）。此外，如果所研究的所有原子结构的bin的PCF值为零（这在任何点云数据集中都很可能发生），则PCA可能会受到秩亏的阻碍，因为没有关于该特定bin的信息来计算包含PCA基础。因此，对于MKS框架在点云原子结构数据集上的应用，**某种形式的平滑是必不可少的。在目前的工作中，这是通过使用Epanechnikov核来实现的，它实际上相当于在每个原子位置周围放置一个球体，然后对体积空间进行离散化，以获得离散化的、但健壮的PCF表示，这有助于建立所需的PSP连接。**

The concept of a “process-structure” relationship for these atomistic simulations would establish a quantitative connection between the process inputs of the simulation and the resulting atomic-scale structure (output). Previous work has established that molecular force-fields can be classified by the resulting atomic structure using 2-point statistics [17], but there has not been a systematic data-driven effort focused on the extraction of reduced order “process-structure” linkages capable of rapidly predicting atomic structures as a function of simulation inputs. If such functions can be established in forms that **require exceptionally low computational cost for their usage, they offer a unique practical approach for addressing inverse problems** where one seeks to identify the process recipes that are likely to result in a desired atomic structure. 

这些原子模拟的“process-structure”关系的概念将在模拟的过程输入和产生的原子尺度结构（输出）之间建立定量联系。以前的工作已经证明，分子力场可以用2点统计法根据得到的原子结构进行分类[17]，但是，目前还没有一个系统的数据驱动的工作集中于提取降阶的“过程-结构”联系，这种联系能够作为模拟输入的函数快速预测原子结构。如果这样的函数可以建立在使用时需要非常低的计算成本的形式，它们为解决反问题提供了一种独特的实用方法，在这种方法中，人们试图确定可能产生所需原子结构的工艺配方。

Another important type of knowledge produced from molecular dynamics/mechanics simulations can be captured effectively in linkages between atomic-scale structure and a relevant property such as the overall system energy; these linkages may be categorized as “structure-property” relationships. In particular, GB energies play a vital role in the multiscale modeling of materials phenomena, as they serve as a key input to simulations at a larger scale (e.g., plasticity [33], failure [34], recrystallization [35]). While **force-field based calculations are significantly less computationally expensive than their quantum-mechanical counterparts**, the datasets often investigated are large in size (10^3 - 10^9 atoms) and high dimensional, and thus cumbersome for use in multiscale models[33,34]. Some progress has been made in training machine learning force fields to results of quantum mechanical methods such as density functional theory for use in molecular dynamics simulations [36e39], but these methods typically require large training sets (10^3 - 10^4 systems), and ultimately MD simulations are still necessary to extract knowledge regarding a system. Data science techniques have also been previously applied for the systematic analysis and knowledge extraction from large MM/MD datasets [40-44] with a focus primarily on proteins and other large biomolecules. Within the materials science community, there has been relatively little effort devoted to a systematic analysis and dimensional reduction of the results of force-field based simulations. This is of particular importance given the recent rise in multiscale and hierarchical methods [1,45]. 

从分子动力学/力学模拟中产生的另一种重要知识类型可以有效地捕捉到原子尺度结构与相关性质（如整个系统能量）之间的联系；这些联系可以归类为“结构-特性”关系。尤其是，GB能量在材料现象的多尺度建模中起着至关重要的作用，因为它们是更大规模模拟的关键输入（例如塑性[33]、失效[34]、再结晶[35]）。虽然**基于力场的计算比量子力学计算的计算成本要低得多**，但研究的数据集通常大（10^3 -10^9 个原子）和高维，因此在多尺度模型中使用非常麻烦[33,34]。在将机器学习力场训练成量子力学方法（如用于分子动力学模拟的密度泛函理论[36e39]）的结果方面已经取得了一些进展，但这些方法通常需要大的训练集（10^3 - 10^4系统），最终，MD模拟仍然是提取有关系统的知识所必需的。数据科学技术以前也被应用于从大型MM/MD数据集中进行系统分析和知识提取[40-44]，主要集中在蛋白质和其他大型生物分子上。在材料科学界，对基于力场的模拟结果进行系统分析和降维的工作相对较少。鉴于最近多尺度和分层方法的兴起，这一点尤为重要[1,45]。

It is emphasized here that one of the main benefits of the data science approaches explored in this work is that they facilitate a systematic and effective learning of the deeply embedded knowledge in the numerical datasets produced by MM/MD simulations. In other words, while MM/MD computations are commonly employed to account for the atomic-scale degrees of freedom within a GB structure [46,47], there is no systematic, data-driven, formalism to capture the knowledge gained from these simulations in forms that allow easy application of the knowledge to new problems. **Given the unimaginably large materials space (including all material chemistries and process variables) that could be covered by the multitude of ongoing disparate efforts of researchers everywhere, it behooves us to consider formalisms that allow extraction, fusion, and curation of the knowledge gained from such efforts.** Indeed, such an advance is essential to enhance and interpret experimental data, pass information between computational models, and rapidly explore large design spaces (by facilitating solutions to inverse problems of interest). The ability to navigate the potential diversity of GB structures in a low dimensional space would provide a facile route to rapidly identify structural regions of interest for additional molecular simulations and connect information between the atomic scale simulations and models at larger length scales. Furthermore, recent developments in microscopy have led to the ability to probe directly the atomic scale structures [48], and diffraction techniques that can be used to measure the PCFs [49,50]; rapid estimation of the energy of an arbitrary GB or atomic structure will allow on-the-fly analysis of these experimental results, providing valuable real-time feedback to the equipment operator [51,52]. This work aims to establish a foundational data science framework that will facilitate these types of future explorations.

本文强调，本研究探索的数据科学方法的一个主要好处是，它们有助于系统和有效地学习MM/MD模拟产生的数值数据集中的深层知识。换言之，虽然MM/MD计算通常用于解释GB结构内的原子尺度自由度[46,47]，但没有系统的、数据驱动的形式主义来获取从这些模拟中获得的知识，使知识能够轻松地应用于新问题。**考虑到难以想象的巨大的材料空间（包括所有材料化学和工艺变量）可以被各地研究人员的大量不同努力所覆盖，我们有必要考虑允许从这些努力中获得的知识的提取、融合和保存的形式。**事实上，这种进步对于增强和解释实验数据、在计算模型之间传递信息、以及快速探索大型设计空间（通过促进感兴趣的反问题的解决方案）至关重要。在低维空间中导航GB结构的潜在多样性的能力将提供一种简便的途径，以快速识别感兴趣的结构区域以进行其他分子模拟，并在原子尺度模拟和更大尺度的模型之间连接信息。此外，最近显微镜技术的发展使人们能够直接探测原子尺度结构[48]，衍射技术可用于测量PCF[49,50]；快速估计任意GB或原子结构的能量将允许对这些实验结果进行动态分析，向设备操作员提供有价值的实时反馈[51,52]。这项工作的目的是建立一个基础数据科学框架，以促进这些类型的未来探索。 

---

The GB atomic structures can be complex and varied, with hundreds or thousands of atoms in the GB per simulation. These structures can be quantified with PCFs [49,50] or more rigorously with 2-point statistics [17], which are equivalent to directionally resolved PCFs. For atomistic GB simulations, **the PCF is a good candidate for use as a structure metric as it is invariant to relative crystal orientation with respect to the reference frame**. Only the atoms identified as GB atoms were included in the PCF computation. As PCFs calculated with a traditional **binning technique proved too rough (sharp) for model fitting**, we employed here a smoothing technique based on kernel density estimation (KDE), as explained next. 

GB的原子结构可以是复杂多变的，每次模拟GB中有数百或数千个原子。这些结构可以用PCF[49,50]或更严格地用2点统计[17]来量化，这等同于定向解析的PCF。对于原子级GB模拟，PCF是一个很好的候选结构度量，因为它是相对于参考坐标系的相对晶体取向不变的。PCF计算中只包括了被识别为GB原子的原子。由于用传统的分块技术计算的pcf对于模型拟合来说过于粗糙（尖锐），我们在这里采用了一种基于核密度估计（KDE）的平滑技术，如下所述。

For each GB atom, the distances to the 134 nearest neighboring atoms (GB or bulk) were found using the k-Nearest Neighbors algorithm [55], and a probability distribution function (PDF) of all neighbor distances for all GB atoms was estimated using KDE [58] with an Epanechnikov kernel. The use of a kernel introduces a smoothing parameter into the PCF; to within a small approximation, a PCF calculated with the Epanechnikov kernel is equivalent to treating each atom as a uniformly dense sphere of finite radius. The Epanechnikov kernel for bandwidth h and distance u along the PDF is: 

对于每个 GB 中的 H 偏聚位点，使用 k-最近邻算法找到截断距离内的所有原子（晶界原子或晶块原子），并使用带有Epanechnikov核的 KDE估计所有 GB 原子所有相邻距离的概率分布函数（PDF）。核的使用在 PCF 中引入了一个平滑参数；在一个小的近似范围内，用 Epanechnikov 核计算的 PCF 相当于将每个原子看作一个半径有限的均匀稠密球体。PDF 中带宽 h 和距离 u 的 Epanechnikov 内核为：
$$
k^e(u,h)=\begin{equation}
\left\{
\begin{aligned}
\frac{3}{4\sqrt{5h^2}}(1-\frac{u^2}{5h^2})\qquad &for\;\, (u/h)^2<5\\
0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \  &\ \ \ \ otherwise\\
\end{aligned}
\right.
\end{equation}
$$
This kernel can be used to construct a PDF using the following equation:
$$
\psi_i(r)=\frac{1}{N_{cutoff}}\sum\limits_{k=1}^{N_{cutoff}}k_e(r-||\vec R_{i,a}^{(k)}||,h_e)
$$
传统的 PCF 采用狄拉克δ函数作为加和项： 
$$
\psi_i'(r)=\frac{1}{N_{cutoff}}\sum\limits_{k=1}^{N_{cutoff}}\delta(r-||\vec R_{i,a}^{(k)}||)
$$
In this equation, $N_{cutoff}$ represents the number of atoms within the cutoff range, $\mathcal{Z}_i^G$ represents the set of trapping sites in the GB, $N_i^G$ represents the number of atoms in this set, $h_e$ is the Epanechnikov kernel bandwidth, and $||\vec R_{i,a}^{(k)}||$ is the magnitude of the displacement vector from trapping site a to its kth nearest atom. **The cutoff radius of 6.3 Å was chosen as it corresponds to the cutoff distance associated with the interatomic potential used in these simulations [59].** A PCF can be expressed in terms of this PDF scaled by the inverse squared distance and appropriate constants. The formulation of the PCF used in this study can be expressed as: 

在这个方程中，$N_{cutoff}$表示截止范围内的原子数，$\mathcal{Z}_i^G$表示GB中的原子间隙集合，$N_i^G$表示该集合中的原子数，$h_e$是 Epanechnikov 内核带宽，$||\vec R_{i,a}^{(k)}||$ 原子到它的最邻近原子的位移。选择 $6.3\ \AA$ 的截止半径是因为它对应于与这些模拟中使用的原子间势相关的截止距离[59]。PCF 可以用由平方反比距离和适当常数缩放的 PDF 表示。本研究中使用的 PCF 配方可表示为： 
$$
\gamma_i(r)=\frac{N_{cutoff}}{4\pi r^2n_0}\psi_i(r)
$$
where, $n_0$ is the atomic number density of bulk crystalline Al ($6.02\times10^{-2}\ Å^{-3}$). For each simulation, the value of **the PCF was calculated (sampled) for 512 equally spaced points from 0 to 6.3 Å.** Fig. 2b depicts an example of one such PCF, in this case a $\Sigma9$ simulation with an inclination angle ($\theta$) of 22.99°. For ATGBs, the inclination angle is the angle between the GB plane and the plane of reflection symmetry between the two crystal lattices. 

其中，$n_0$是晶体 Al 的原子数密度。($6.02\times10^{-2}\ Å^{-3}$)。 对于每个模拟，**计算（采样）512个 0 to 6.3 Å 的等间距点的值**。图 2b 描述了一个这样的 PCF 的示例，在这种情况下，一个 $\Sigma9$ 模拟，倾角（$\theta$）为22.99°。对于ATGBs，倾斜角是两个晶格之间的 GB 平面和反射对称平面之间的夹角。

简单的说，径向分布函数是用来描述某个所研究粒子周围其他粒子分布情况的物理量，其积分代表平均配位数。对本研究而言，计算经过 KDE 改进的 PCF 函数可以提供一个 
$$
N^{GB}\ atoms\times N^{PCF}\ samples
$$
大小的高维数据数组。

Although the PCF represents a detailed quantification of the atomic structure, this is still a high-dimensional data structure (equal to the number of points where the PCF is sampled) to allow computationally efficient comparison of different GBs and the establishment of correlations with either the GB energy or the GB macro degrees of freedom. This is where dimensionality reduction techniques can prove valuable. After subtracting the mean PCF from the discretely sampled PCFs of all simulations, principal component analysis (PCA)[60] was performed via the singular value decomposition. PCA is a common technique for dimensional reduction that determines an orthogonal basis for the data where ith eigen vector corresponds to the direction with the ith largest variance, as illustrated in Fig. 3a [2]. 

尽管 PCF 代表了原子结构的详细量化，但这仍然是一种高维数据结构（相当于 PCF 采样点的数量），以便在计算上有效地比较不同的GBs，并建立与 GB 能量或 GB 宏观自由度的相关性。这就是维数缩减技术可以证明是有价值的。从所有模拟的离散采样 PCF 中减去平均 PCF 后，通过奇异值分解进行主成分分析（PCA）[60]。PCA 是用于降维的常用技术，其确定数据的正交基，其中第 i 个特征向量对应于具有第 i 个最大方差的方向，如图 3a[2] 所示。
$$
\left\{
    \begin{array}{l}
    \frac{3}{4\sqrt{5h^2}}(1-\frac{u^2}{5h^2})\qquad &for\;\, (u/h)^2<5 \\  \ \ \ \ \ \ \ \ \ \ \ \ 0  &   \ \ \ \ otherwise
     \end{array}
\right.
$$
In this case, the input dataset for PCA is the entire ensemble of PCFs for all Al ATGB simulations, and Fig. 3b depicts eigenvectors 1, 2, 3, and 6 of the dataset. Truncating a PCA representation of a structure at the kth value/vector yields the best possible rank-k approximation to the full dataset. This provides a systematic way to represent a high-dimensional structure in a low-dimensional space while still preserving a well-defined amount of variance from the entire system. After a low-dimensional subspace has been defined, all datasets can naturally be projected onto this subspace; the new coordinates provide their PC scores. Furthermore, given any arbitrary point in this PC space it is straightforward to reconstruct the PCF corresponding to the point by using a linear combination of the appropriate PC vectors weighted with the scores corresponding to the point in low-dimensional space. Thus, the low-dimensional representation of the atomic structure provides a route for not only analyzing existing datasets, but also for predicting full atomic structures with properties interpolated between the given data using, e.g., reverse Monte Carlo methods. 

在这种情况下，PCA 的输入数据集是所有 Al-ATGB 模拟的 PCF 的整个集合，图 3b 描绘了数据集的特征向量 1、2、3 和 6 。在第 k 个值/向量处截断一个结构的 PCA 表示可以得到对整个数据集的最佳 rank-k 近似。这为在低维空间中表示高维结构提供了一种系统化的方法，同时仍然保留了整个系统中定义良好的方差量。定义了低维子空间后，所有数据集都可以自然地投影到该子空间上；新的坐标提供了它们的 PC 分数。此外，给定 PC 空间中的任意点，通过使用适当的 PC 向量与低维空间中对应点的分数加权的线性组合，可以直接重建与该点对应的 PCF。因此，原子结构的低维表示不仅为分析现有的数据集提供了一条途径，而且还提供了一条途径，用于预测具有给定数据之间的属性的完整原子结构，例如使用反向蒙特卡罗方法。

---

#### Results and discussion

The Epanechnikov kernel bandwidth serves as a modeling hyperparameter, and the value chosen for the PCF calculation (0.42 Å) corresponds to the error minimum in the full PSP model and full dataset, as illustrated in Fig. 4. This is roughly equivalent to treating each atom as a uniformly dense sphere with a radius of $0.42*\sqrt{5}= 0.94\ Å$ (about 2/3 the atomic radius of crystalline Al) rather than as a point particle. However, given the relatively wide well depicted in Fig. 4, any bandwidth from ca. $0.35-0.5$ would increase the error by $<1 mJ/m^2$ , **indicating that overfitting is not a concern for this hyperparameter selection**. We first examine the structure-property model obtained by regression between the PC values and the associated grain boundary energy. The $R^2$ value associated with our two-component (PCs 1 and 6) structure-property regression model is 0.98, with PC 1 accounting for 96% of the explained variance. The inclusion of the third-best principal component in terms of fitting (PC 4) did not appreciably improve the fit. The fitting function is presented in Equation (5), where $\widehat E_i$ is the predicted energy and $T_{i1}$ and $T_{i6}$ are the scores corresponding to PCs 1 and 6, respectively. 

Epanechnikov内核带宽用作建模超参数，为 PCF 计算选择的值（0.42Å）对应于完整 PSP 模型和完整数据集中的最小误差，如图 4 所示。这大致等同于处理每个原子是半径为 $ 0.42*\sqrt{5}=0.94\ Å$ 的 均匀致密球体（大约是晶体 Al 原子半径的2/3），而不是作为点粒子。然而，从图 4 中描述的误差-核宽度关系， $ 0.35-0.5\ \AA$ 之间的核宽度仅仅使误差增加 $ <1 mJ / m ^ 2 $，这表明可能的过拟合问题与该超参数选择无关。我们首先检查通过 PC 值和相关的晶界能之间的回归获得的结构属性模型。与我们的两部分（PC 1和6）结构属性回归模型相关的$ R ^ 2 $值为 0.98，其中 PC1占解释方差的 96％。就拟合度（PC 4）而言，第三主成分的加入并没有明显改善拟合能力。拟合函数在等式（5）中给出，其中$ \widehat E_i $是预测能量，$ T_ {i1} $和$ T_ {i6} $分别是对应于PC1 和 PC6 的分数。
$$
\widehat E_i(mJ\cdot m^{-2})\approx-548.66\cdot T_{i1}-1070.89\cdot T_{i6}+387.55
$$
Fig. 5a shows a parity plot of the GB energies predicted by the regression model plotted against the values computed from the full simulations. The mean absolute value of the error in prediction is roughly $11.4 mJ/m^2$ . This is substantially less than the error in prediction of simulation versus experiment over a large range of $\theta$ as shown in the original dataset (see Ref. [46], Fig. 1). 

图 5a 显示出了回归模型预测值和实际模拟值间的图。预测误差的平均绝对值约为$ 11.4 mJ / m ^ 2 $。如原始数据集所示，这大大小于在较大的 $\theta $ 范围内模拟与实验的预测误差（参见参考文献[46]，图1）。

Fig. 5b shows a Box-Whisker plot of the mean absolute errors from 1000 instances of 3-fold cross-validation. The box represents the interquartile range, and the dashed ‘whiskers’ have a length 1.5 times that of the interquartile range; points outside this range represented as dots are considered outliers. This shows that, even in the case of extreme outliers, the prediction error is still fairly small ($<13 mJ/m^2$ ). Given that the accuracy of GB energies computed with force-field models can be on the order of $50 mJ/m^2$ when compared to experiment [46], this result indicates that the method will be able to serve as an efficient and reliable surrogate to expensive molecular mechanics models for GB energies. Additionally, this plot confirms that the model has not been over-fitted.

图 5b 显示了 1000 个样本下 3 折交叉验证平均绝对误差的 Box-Whisker 图。方框代表四分位间距，虚线 “须晶” 的长度是四分位间距的 1.5 倍；以点表示的超出此范围的点被视为离群值。这表明，即使在极端离群值的情况下，预测误差仍然很小（$ <13 mJ / m ^ 2 $）。假设与实验[46]相比，用力场模型计算出的 GB 能量的精度大约为$ 50 mJ / m ^ 2 $，该结果表明该方法将能够有效而可靠地发挥作用。替代了 GB 能量的昂贵分子力学模型。此外，该图还表明该模型尚未过拟合。

The accuracy of the structure-property relationship is remarkable given its simplicity. The PCF represents a substantial compression of information from the full atomic structure, and the fact that the PCF is correlated to the energy through a linear model with only two principal components is noteworthy. However, inspection of the underlying interatomic potential yields some insight into this finding. The potential applied in this work is based on the embedded atom model [62,63]: 

考虑到它的简单性，结构-属性关系的准确性非常出色。 PCF 代表了来自完整原子结构的大量信息压缩，并且值得注意的是，PCF 通过仅具有两个主要成分的线性模型与能量相关。但是，对潜在的原子间电势的检查可以使您对该发现有所了解。在这项工作中应用的潜力基于嵌入式原子模型 [62,63]：
$$
E^{tot}=\frac{1}{2}\sum\limits_{a}\sum\limits_{\tilde a \neq  a}\Phi_{a\tilde a}(r_{a\tilde a})+\sum\limits_{\tilde a\neq a}\rho_{\tilde a}(r_{a\tilde a})
$$
where $E^{tot}$ is the energy of the system, $\Phi_{a\tilde a}$ is an interatomic pair potential, $\rho_{\tilde a}$ is the “atomic electron density” function, $\eta_a$ is the embedding energy function, and $r_{a\tilde a}$ is the distance between atoms a and $\tilde a$ . Inspection of the expression reveals that the interatomic distance, $r_{a\tilde a}$, is the fundamental variable of both summation terms. **The fact that the PCF is a function of the probability distribution of $r_{a\tilde a}$ (see Equation (4)) provides a strong mathematical justification for its ability to accurately predict energies based on the embedded** atom model, and suggests that the accuracy of the approach will generalize to other similar potentials where the interatomic distance is the fundamental variable [64,65]. However, it should be noted that **a regression model constructed using PCFs calculated by a traditional binning technique had relatively weak predictive power.** This means that a predictive model must <u>be robust against structural variance as pertaining to small local changes in atomic position</u>, which are diminished by the smoothing parameter in KDE-derived PCFs. 

其中$ E ^ {tot} $是系统的能量，$ \Phi_ {a \tilde a} $是原子间的对势，$ \rho _ {\tilde a} $ 是“原子电子密度”函数，$ \eta_a $ 是嵌入能量函数，$ r_{a \tilde a} $是原子 a 与 $\tilde a$ 之间的距离。对表达式的检查表明，原子间距离 $r_{a\tilde a}$ 是两个求和项的基本变量。 **PCF 是 $r_{a\ tilde a}$ 的概率分布的函数（请参见等式（4））这一事实为基于嵌入原子精确预测能量的能力提供了强有力的数学依据。** 并暗含该方法的准确性将推广到其他类似的潜力，其中原子间距离是基本变量[64,65]。但是，应该注意的是，使**用传统方法计算出的 PCF 构建的回归模型的预测能力相对较弱。**这意味着，<u>预测模型必须能够抵抗与局部小变化有关的结构变异。原子位置</u>，它会因KDE衍生的PCF中的平滑参数而减小。

